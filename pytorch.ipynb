{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pytorch Tutorial\n",
    "\n",
    "Notebook available here: https://github.com/jakobottar/pytorch-tutorial\n",
    "\n",
    "Get cat image data here: https://www.dropbox.com/s/y1cxgxec95e181a/cat_images.zip?dl=0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyTorch Background\n",
    "\n",
    "Data in PyTorch is stored in Tensors, which are almost identical to NumPy arrays.\n",
    "\n",
    "Their key differences are\n",
    "1. Auto gradient calculation (with `torch.autograd`)\n",
    "2. Ability to move to a GPU (with `Tensor.to(device)`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "data = [[1,2,3], [4,5,6], [7,8,9]]\n",
    "data_tensor = torch.tensor(data)\n",
    "print(data_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ones_tensor = torch.ones(size=data_tensor.shape, dtype=int)\n",
    "print(ones_tensor)\n",
    "\n",
    "# these tensors behave almost exactly like numpy arrays\n",
    "print(ones_tensor @ data_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets & DataLoaders\n",
    "\n",
    "Some datasets are available from Pytorch's own libraries, such as MNIST or Fashion-MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "training_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")\n",
    "\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")\n",
    "\n",
    "print(training_data)\n",
    "print(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_map = {\n",
    "    0: \"T-Shirt\",\n",
    "    1: \"Trouser\",\n",
    "    2: \"Pullover\",\n",
    "    3: \"Dress\",\n",
    "    4: \"Coat\",\n",
    "    5: \"Sandal\",\n",
    "    6: \"Shirt\",\n",
    "    7: \"Sneaker\",\n",
    "    8: \"Bag\",\n",
    "    9: \"Ankle Boot\",\n",
    "}\n",
    "\n",
    "figure = plt.figure(figsize=(8, 8))\n",
    "cols, rows = 2, 3\n",
    "for i in range(1, cols * rows + 1):\n",
    "    sample_idx = torch.randint(len(training_data), size=(1,)).item()\n",
    "    img, label = training_data[sample_idx]\n",
    "    figure.add_subplot(rows, cols, i)\n",
    "    plt.title(labels_map[label])\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(img.squeeze(), cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can make custom datasets for your own images easily, just make a child instance of the `torch.utils.data.Dataset` class and implement the following functions:\n",
    "- `__init__()`: one-time setup of the class, aka the *Constructor*.\n",
    "- `__len__()`: length of the dataset, used when you call `len(dataset)`.\n",
    "- `__getitem__()`: what runs when you get an item out of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torchvision.io import read_image\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "class NoiseDataset(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        csv_file=\"TrainingDataSet.csv\",\n",
    "        root_dir_noisy=\"TrainingDataSet\",\n",
    "        root_dir_ref=\"./\",\n",
    "        transform=None,\n",
    "    ):\n",
    "        # read csv file\n",
    "        self.name_csv = pd.read_csv(csv_file)\n",
    "\n",
    "        # store attributes\n",
    "        self.root_dir_noisy = root_dir_noisy\n",
    "        self.root_dir_ref = root_dir_ref\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.name_csv)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        # get image filenames\n",
    "        ref_img_name = os.path.join(self.root_dir_ref, self.name_csv.iloc[idx, 0])\n",
    "        noisy_img_name = os.path.join(self.root_dir_noisy, self.name_csv.iloc[idx, 2])\n",
    "\n",
    "        # load images\n",
    "        ref_image = read_image(ref_img_name)\n",
    "        noisy_image = read_image(noisy_img_name)\n",
    "\n",
    "        # apply transforms\n",
    "        if self.transform:\n",
    "            ref_image = self.transform(ref_image)\n",
    "            noisy_image = self.transform(noisy_image)\n",
    "        return noisy_image, ref_image\n",
    "        \n",
    "cats_dataset = NoiseDataset(\n",
    "            csv_file=\"data/cats/training.csv\",\n",
    "            root_dir_noisy=\"data/cats/training\",\n",
    "        )\n",
    "\n",
    "\n",
    "print(f\"len(cats_dataset): {len(cats_dataset)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to load the datasets into the model, you need wrap them in a `torch.utils.data.DataLoader` class, which handles batches and shuffling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# FashionMNIST datasets\n",
    "train_dataloader = DataLoader(training_data, batch_size=64, shuffle=True)\n",
    "test_dataloader = DataLoader(test_data, batch_size=64, shuffle=True)\n",
    "\n",
    "# custom cats dataset\n",
    "cats_dataloader = DataLoader(cats_dataset, batch_size=3, shuffle=True)\n",
    "\n",
    "# pull a batch off and look at it\n",
    "noisy_images, ref_images = next(iter(cats_dataloader))\n",
    "print(f\"noisy_images.shape: {noisy_images.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure = plt.figure(figsize=(6, 8))\n",
    "rows = noisy_images.shape[0]\n",
    "for i in range(0, rows):\n",
    "    figure.add_subplot(rows, 2, (2 * i) + 1)\n",
    "    plt.title(\"Noisy\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(noisy_images[i].squeeze(), cmap=\"gray\")\n",
    "\n",
    "    figure.add_subplot(rows, 2, (2 * i) + 2)\n",
    "    plt.title(\"Reference\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(ref_images[i].squeeze(), cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transforms\n",
    "\n",
    "Sometimes the images you're given are not in the right format for training or you want to do some image augmentation before you put them into a neural net. This is where transforms come in. There's a whole list of transformations you can use ([pytorch.org/vision/stable/transforms.html](https://pytorch.org/vision/stable/transforms.html)), ranging from resizing and cropping to color shifting and blurring. \n",
    "\n",
    "`transforms.ToTensor()` can be very useful to convert data from whatever form you loaded as to a Tensor. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "\n",
    "# compose multiple transforms like this\n",
    "transform = transforms.Compose(\n",
    "        [\n",
    "            transforms.Resize((64, 64)),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "# they're applied at the dataset level\n",
    "cats_dataset = NoiseDataset(\n",
    "            csv_file=\"data/cats/training.csv\",\n",
    "            root_dir_noisy=\"data/cats/training\",\n",
    "            transform=transform\n",
    "        )\n",
    "\n",
    "cats_dataloader = DataLoader(cats_dataset, batch_size=3, shuffle=True)\n",
    "\n",
    "noisy_images, ref_images = next(iter(cats_dataloader))\n",
    "\n",
    "figure = plt.figure(figsize=(6, 8))\n",
    "rows = noisy_images.shape[0]\n",
    "for i in range(0, rows):\n",
    "    figure.add_subplot(rows, 2, (2 * i) + 1)\n",
    "    plt.title(\"Noisy\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(noisy_images[i].squeeze(), cmap=\"gray\")\n",
    "\n",
    "    figure.add_subplot(rows, 2, (2 * i) + 2)\n",
    "    plt.title(\"Reference\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(ref_images[i].squeeze(), cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "# the model can run on either CPU or CUDA (also supports AMD's ROCm)\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can define a model by making a child instance of the the `nn.Module` class. All network layers are derived from the `nn.Module` class. You need to implement the following functions:\n",
    "- `__init__()`: same as with the Dataset, one-time setup.\n",
    "- `forward()`: what happens when you want to pass data through the model, a *forward* pass."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28*28, 512), # input images are 28px by 28px\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10), # there are 10 output classes\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "\n",
    "\n",
    "model = NeuralNetwork().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimization and Hyperparameters \n",
    "You'll need to set hyperparameters, as well as initialize your loss function and optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set hyperparameters\n",
    "learning_rate = 1e-3\n",
    "batch_size = 64\n",
    "epochs = 5\n",
    "\n",
    "# initialize loss function\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "# initialize optimizer\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and Testing\n",
    "\n",
    "Here's where the magic happens. You need to write some code to handle training and testing the model. Best practice is to do this in two functions like shown here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        # zero gradients from previous step\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # compute prediction and loss\n",
    "        pred = model(X) # Remember forward()? This calls that.\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 200 == 0: # print some status info\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "\n",
    "def test_loop(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss, correct = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            # compute prediction and loss\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "\n",
    "            # compare predictions and labels\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train_loop(train_dataloader, model, loss_fn, optimizer)\n",
    "    test_loop(test_dataloader, model, loss_fn)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving the model\n",
    "Once you're done training the model, you should probably save it to use in the future. There are two ways to save it, either the whole object (larger file size), or by weights only (need to load model object before applying weights). Either method works, and you can choose how you want to handle saving and loading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model object\n",
    "torch.save(model, 'model.pth')\n",
    "model2 = torch.load('model.pth')\n",
    "\n",
    "# save model weights\n",
    "torch.save(model.state_dict(), \"model-weights.pth\")\n",
    "model3 = NeuralNetwork() # load new model object\n",
    "model3.load_state_dict(torch.load(\"model-weights.pth\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit ('pt')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5249130b4a8b1f011aeb3ad7b3bb5f9322c23532670ca8cb011635d51befc703"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
